<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Numberns</title>
    <style>
      html, body {
        font-size: 16px;
        font-family: Verdana, sans-serif;
      }
      h1, h2 {
        text-align: center;
      }
    </style>
  </head>
  <body>
    <h1>JavaScript Numbers</h1>
      <p>
        JavaScript has only one type of number. Numbers can be written with, or without, decimals.
      </p>
      <p>
        <code>
          <strong>Exemplo:</strong><br>
          var x = 30.00; &nbsp;&nbsp;//A number with decimals<br>
          var y = 30; &nbsp;&nbsp;&nbsp;&nbsp;//A number without decimals.
        </code>
      </p>
      <p>
        Extra large or extra small numbers can be written with scientific (exponent) notation:
      </p>
      <p>
        <code>
          <strong>Exemplo:</strong><br>
          var x = 123e5; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// 12300000<br>
          var y = 123e-5;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// 0.00123
        </code>
      </p><hr>

    <h2>JavaScript Numbers are Always 64-bit Floating Point</h2>
      <p>
        Unlike many other programming languages, JavaScript does not define different types of numbers, like integers, short, long, floating-point etc.
      <p>
      <p>
        JavaScript numbers are always stored as double precision floating point numbers, following the international IEEE 754 standard.
      </p>
      <p>
        This format stores numbers in 64 bits, where the number (the fraction) is stored in bits 0 to 51, the exponent in bits 52 to 62, and the sign in bit 63:
      </p>
      <table>
        <tr>
          <th>Value (aka Fraction/Mantissa)</th>
          <th>Exponet</th>
          <th>Sign</th>
        </tr>
        <tr>
          <td>52 bits (0 - 51)</td>
          <td>11 bits (52 - 62)</td>
          <td>1 bit (63)</td>
        </tr>
      </table><hr>
    <h2>Precision</h2>
      <p>
        Integers (numbers without a period or exponent notation) are considered accurate up to 15 digits.
      </p>
      <p>
        <code>
          var x = 999999999999999;   // x will be 999999999999999<br>
          var y = 9999999999999999;  // y will be 10000000000000000
        </code>
      </p>
      <p>
        The maximum number of decimals is 17, but floating point arithmetic is not always 100% accurate:
      </p>
      <p>
        Floating point arithmetic is not always 100% accurate.
      </p>
      <button onclick="myFunction()">Try it</button>
      <p id="demo"></p>
      <hr>
    <h2>Hexadecimal</h2>
      <p>
        JavaScript interprets numeric constants as hexadecimal if they are preceded by 0x.
      </p>
      <button name="button" onclick="conversao()">Clique-me!</button>
      <p id="demo2"></p>

    <!--Code JavaScript-->
    <script type="text/javascript">
      src="JS/19_Numbers.js"
    </script>
  </body>
</html>
